overlay: 1.0.0
info:
  title: CodeSamples overlay for python target
  version: 0.0.0
actions:
  - target: $["paths"]["/health"]["get"]
    update:
      x-codeSamples:
        - lang: python
          label: health
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.health.health()

                # Handle response
                print(res)
  - target: $["paths"]["/v1/chat/completions"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: chat_completions_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                completion = atoma_sdk.chat.create(
                  model="meta-llama/Llama-3.3-70B-Instruct",
                  messages=[
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
  - target: $["paths"]["/v1/chat/completions#stream"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: chat_completions_create_stream
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                completion = atoma_sdk.chat.create_stream(
                  model="meta-llama/Llama-3.3-70B-Instruct",
                  messages=[
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                for chunk in completion:
                  print(chunk.data.choices[0].delta)
  - target: $["paths"]["/v1/confidential/chat/completions"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: confidential_chat_completions_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                completion = atoma_sdk.confidential_chat.create(
                  model="meta-llama/Llama-3.3-70B-Instruct",
                  messages=[
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
  - target: $["paths"]["/v1/confidential/chat/completions#stream"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: confidential_chat_completions_create_stream
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                completion = atoma_sdk.confidential_chat.create_stream(
                  model="meta-llama/Llama-3.3-70B-Instruct",
                  messages=[
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                for chunk in completion:
                  print(chunk.choices[0].delta)
  - target: $["paths"]["/v1/confidential/embeddings"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: confidential_embeddings_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.confidential_embeddings.create(
                  input_="The quick brown fox jumped over the lazy dog",
                  model="intfloat/multilingual-e5-large-instruct",
                  encoding_format="float"
                )

                print(res)
  - target: $["paths"]["/v1/confidential/images/generations"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: confidential_image_generations_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.confidential_images.generate(
                  model="black-forest-labs/FLUX.1-schnell",
                  prompt="A cute baby sea otter floating on its back",
                  n=1,
                  quality="hd",
                  response_format="url",
                  size="1024x1024"
                )

                print(res)
  - target: $["paths"]["/v1/embeddings"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: embeddings_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.embeddings.create(
                  input_="The quick brown fox jumped over the lazy dog",
                  model="intfloat/multilingual-e5-large-instruct",
                  encoding_format="float"
                )

                print(res)
  - target: $["paths"]["/v1/images/generations"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: image_generations_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.images.generate(
                  model="black-forest-labs/FLUX.1-schnell",
                  prompt="A cute baby sea otter floating on its back",
                  n=1,
                  quality="hd",
                  response_format="url",
                  size="1024x1024"
                )

                print(res)
  - target: $["paths"]["/v1/models"]["get"]
    update:
      x-codeSamples:
        - lang: python
          label: models_list
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.models.models_list()

                # Handle response
                print(res)
  - target: $["paths"]["/v1/nodes"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: nodes_create
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.nodes.nodes_create(data={
                    "country": "Andorra",
                    "node_small_id": 3665,
                    "public_address": "<value>",
                }, signature="<value>")

                # Handle response
                print(res)
  - target: $["paths"]["/v1/nodes/lock"]["post"]
    update:
      x-codeSamples:
        - lang: python
          label: nodes_create_lock
          source: |-
            from atoma_sdk import AtomaSDK
            import os

            with AtomaSDK(
                bearer_auth=os.getenv("ATOMASDK_BEARER_AUTH", ""),
            ) as atoma_sdk:

                res = atoma_sdk.nodes.nodes_create_lock(model="Focus")

                # Handle response
                print(res)
