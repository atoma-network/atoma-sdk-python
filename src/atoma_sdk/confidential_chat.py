"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from atoma_sdk import models, utils
from atoma_sdk._hooks import HookContext
from atoma_sdk.types import OptionalNullable, UNSET
from atoma_sdk.utils import get_security_from_env
from typing import Mapping, Optional


class ConfidentialChat(BaseSDK):
    r"""Atoma's API confidential chat completions v1 endpoint"""

    def create(
        self,
        *,
        ciphertext: str,
        client_dh_public_key: str,
        nonce: str,
        plaintext_body_hash: str,
        salt: str,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.ConfidentialChatCompletionResponse:
        r"""Create confidential chat completion

        This handler processes chat completion requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.

        # Arguments

        * `metadata` - Extension containing request metadata including:
        * `endpoint` - The API endpoint being accessed
        * `node_address` - Address of the inference node
        * `node_id` - Identifier of the selected node
        * `num_compute_units` - Available compute units
        * `selected_stack_small_id` - Stack identifier
        * `salt` - Optional salt for encryption
        * `node_x25519_public_key` - Optional public key for encryption
        * `model_name` - Name of the AI model being used
        * `state` - Shared application state (ProxyState)
        * `headers` - HTTP request headers
        * `payload` - The chat completion request body

        # Returns

        Returns a `Result` containing either:
        * An HTTP response with the chat completion result
        * A streaming SSE connection for real-time completions
        * A `StatusCode` error if the request processing fails

        # Errors

        Returns `StatusCode::BAD_REQUEST` if:
        * The 'stream' field is missing or invalid in the payload

        Returns `StatusCode::INTERNAL_SERVER_ERROR` if:
        * The inference service request fails
        * Response processing encounters errors
        * State manager updates fail

        # Security Features

        * Utilizes AEAD encryption for request/response data
        * Supports TEE (Trusted Execution Environment) processing
        * Implements secure key exchange using X25519
        * Maintains confidentiality throughout the request lifecycle

        # Example

        ```rust,ignore
        let response = confidential_chat_completions_handler(
        Extension(metadata),
        State(state),
        headers,
        Json(payload)
        ).await?;
        ```

        :param ciphertext: The encrypted CreateChatCompletionRequest
        :param client_dh_public_key: Client's DH public key for key exchange
        :param nonce: Nonce used for encryption
        :param plaintext_body_hash: Hash of the plaintext body for verification
        :param salt: Salt used for encryption
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url

        request = models.ConfidentialChatCompletionRequest(
            ciphertext=ciphertext,
            client_dh_public_key=client_dh_public_key,
            nonce=nonce,
            plaintext_body_hash=plaintext_body_hash,
            salt=salt,
        )

        req = self.build_request(
            method="POST",
            path="/v1/confidential/chat/completions",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.ConfidentialChatCompletionRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                operation_id="confidential_chat_completions_create",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(
                http_res.text, models.ConfidentialChatCompletionResponse
            )
        if utils.match_response(http_res, ["400", "401", "4XX", "500", "5XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = utils.stream_to_text(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )

    async def create_async(
        self,
        *,
        ciphertext: str,
        client_dh_public_key: str,
        nonce: str,
        plaintext_body_hash: str,
        salt: str,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.ConfidentialChatCompletionResponse:
        r"""Create confidential chat completion

        This handler processes chat completion requests in a confidential manner, providing additional
        encryption and security measures for sensitive data processing. It supports both streaming and
        non-streaming responses while maintaining data confidentiality through AEAD encryption and TEE hardware,
        for full private AI compute.

        # Arguments

        * `metadata` - Extension containing request metadata including:
        * `endpoint` - The API endpoint being accessed
        * `node_address` - Address of the inference node
        * `node_id` - Identifier of the selected node
        * `num_compute_units` - Available compute units
        * `selected_stack_small_id` - Stack identifier
        * `salt` - Optional salt for encryption
        * `node_x25519_public_key` - Optional public key for encryption
        * `model_name` - Name of the AI model being used
        * `state` - Shared application state (ProxyState)
        * `headers` - HTTP request headers
        * `payload` - The chat completion request body

        # Returns

        Returns a `Result` containing either:
        * An HTTP response with the chat completion result
        * A streaming SSE connection for real-time completions
        * A `StatusCode` error if the request processing fails

        # Errors

        Returns `StatusCode::BAD_REQUEST` if:
        * The 'stream' field is missing or invalid in the payload

        Returns `StatusCode::INTERNAL_SERVER_ERROR` if:
        * The inference service request fails
        * Response processing encounters errors
        * State manager updates fail

        # Security Features

        * Utilizes AEAD encryption for request/response data
        * Supports TEE (Trusted Execution Environment) processing
        * Implements secure key exchange using X25519
        * Maintains confidentiality throughout the request lifecycle

        # Example

        ```rust,ignore
        let response = confidential_chat_completions_handler(
        Extension(metadata),
        State(state),
        headers,
        Json(payload)
        ).await?;
        ```

        :param ciphertext: The encrypted CreateChatCompletionRequest
        :param client_dh_public_key: Client's DH public key for key exchange
        :param nonce: Nonce used for encryption
        :param plaintext_body_hash: Hash of the plaintext body for verification
        :param salt: Salt used for encryption
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url

        request = models.ConfidentialChatCompletionRequest(
            ciphertext=ciphertext,
            client_dh_public_key=client_dh_public_key,
            nonce=nonce,
            plaintext_body_hash=plaintext_body_hash,
            salt=salt,
        )

        req = self.build_request_async(
            method="POST",
            path="/v1/confidential/chat/completions",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.ConfidentialChatCompletionRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                operation_id="confidential_chat_completions_create",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(
                http_res.text, models.ConfidentialChatCompletionResponse
            )
        if utils.match_response(http_res, ["400", "401", "4XX", "500", "5XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = await utils.stream_to_text_async(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )
