"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from atoma_sdk import models, utils
from atoma_sdk._hooks import HookContext
from atoma_sdk.types import OptionalNullable, UNSET
from atoma_sdk.utils import get_security_from_env
from typing import Any, Mapping, Optional


class Models(BaseSDK):
    r"""OpenAI's API models v1 endpoint"""

    def models_handler(
        self,
        *,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Any:
        r"""List models

        This endpoint mimics the OpenAI models endpoint format, returning a list of
        available models with their associated metadata and permissions. Each model
        includes standard OpenAI-compatible fields to ensure compatibility with
        existing OpenAI client libraries.

        # Arguments

        * `state` - The shared application state containing the list of available models

        # Returns

        Returns a JSON response containing:
        * An \"object\" field set to \"list\"
        * A \"data\" array containing model objects with the following fields:
        - id: The model identifier
        - object: Always set to \"model\"
        - created: Timestamp (currently hardcoded)
        - owned_by: Set to \"atoma\"
        - root: Same as the model id
        - parent: Set to null
        - max_model_len: Maximum context length (currently hardcoded to 2048)
        - permission: Array of permission objects describing model capabilities

        # Example Response

        ```json
        {
        \"object\": \"list\",
        \"data\": [
        {
        \"id\": \"meta-llama/Llama-3.1-70B-Instruct\",
        \"object\": \"model\",
        \"created\": 1730930595,
        \"owned_by\": \"atoma\",
        \"root\": \"meta-llama/Llama-3.1-70B-Instruct\",
        \"parent\": null,
        \"max_model_len\": 2048,
        \"permission\": [
        {
        \"id\": \"modelperm-meta-llama/Llama-3.1-70B-Instruct\",
        \"object\": \"model_permission\",
        \"created\": 1730930595,
        \"allow_create_engine\": false,
        \"allow_sampling\": true,
        \"allow_logprobs\": true,
        \"allow_search_indices\": false,
        \"allow_view\": true,
        \"allow_fine_tuning\": false,
        \"organization\": \"*\",
        \"group\": null,
        \"is_blocking\": false
        }
        ]
        }
        ]
        }
        ```

        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        req = self.build_request(
            method="GET",
            path="/v1/models",
            base_url=base_url,
            url_variables=url_variables,
            request=None,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                operation_id="models_handler",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(http_res.text, Any)
        if utils.match_response(http_res, ["4XX", "500", "5XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = utils.stream_to_text(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )

    async def models_handler_async(
        self,
        *,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Any:
        r"""List models

        This endpoint mimics the OpenAI models endpoint format, returning a list of
        available models with their associated metadata and permissions. Each model
        includes standard OpenAI-compatible fields to ensure compatibility with
        existing OpenAI client libraries.

        # Arguments

        * `state` - The shared application state containing the list of available models

        # Returns

        Returns a JSON response containing:
        * An \"object\" field set to \"list\"
        * A \"data\" array containing model objects with the following fields:
        - id: The model identifier
        - object: Always set to \"model\"
        - created: Timestamp (currently hardcoded)
        - owned_by: Set to \"atoma\"
        - root: Same as the model id
        - parent: Set to null
        - max_model_len: Maximum context length (currently hardcoded to 2048)
        - permission: Array of permission objects describing model capabilities

        # Example Response

        ```json
        {
        \"object\": \"list\",
        \"data\": [
        {
        \"id\": \"meta-llama/Llama-3.1-70B-Instruct\",
        \"object\": \"model\",
        \"created\": 1730930595,
        \"owned_by\": \"atoma\",
        \"root\": \"meta-llama/Llama-3.1-70B-Instruct\",
        \"parent\": null,
        \"max_model_len\": 2048,
        \"permission\": [
        {
        \"id\": \"modelperm-meta-llama/Llama-3.1-70B-Instruct\",
        \"object\": \"model_permission\",
        \"created\": 1730930595,
        \"allow_create_engine\": false,
        \"allow_sampling\": true,
        \"allow_logprobs\": true,
        \"allow_search_indices\": false,
        \"allow_view\": true,
        \"allow_fine_tuning\": false,
        \"organization\": \"*\",
        \"group\": null,
        \"is_blocking\": false
        }
        ]
        }
        ]
        }
        ```

        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        req = self.build_request_async(
            method="GET",
            path="/v1/models",
            base_url=base_url,
            url_variables=url_variables,
            request=None,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                operation_id="models_handler",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(http_res.text, Any)
        if utils.match_response(http_res, ["4XX", "500", "5XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = await utils.stream_to_text_async(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )
